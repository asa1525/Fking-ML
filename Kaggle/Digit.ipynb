{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasets/digit/train.csv\")\n",
    "test = pd.read_csv('datasets/digit/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train\n",
    "X_test=test\n",
    "Y_train=train[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_train, Y_train, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Xtrain.label\n",
    "X = Xtrain.drop(['label'],axis=1)\n",
    "val_y = Xtest.label\n",
    "val_X = Xtest.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_val = xgb.DMatrix(val_X, label = val_y)\n",
    "xgb_train = xgb.DMatrix(X, label = y)\n",
    "xgb_test = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.086293\tval-merror:0.125238\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.062891\tval-merror:0.098333\n",
      "[2]\ttrain-merror:0.054898\tval-merror:0.087302\n",
      "[3]\ttrain-merror:0.050238\tval-merror:0.080397\n",
      "[4]\ttrain-merror:0.047245\tval-merror:0.078333\n",
      "[5]\ttrain-merror:0.046497\tval-merror:0.07619\n",
      "[6]\ttrain-merror:0.044014\tval-merror:0.074444\n",
      "[7]\ttrain-merror:0.043673\tval-merror:0.072143\n",
      "[8]\ttrain-merror:0.042959\tval-merror:0.072063\n",
      "[9]\ttrain-merror:0.042279\tval-merror:0.071508\n",
      "[10]\ttrain-merror:0.041395\tval-merror:0.070159\n",
      "[11]\ttrain-merror:0.040952\tval-merror:0.070159\n",
      "[12]\ttrain-merror:0.040442\tval-merror:0.070794\n",
      "[13]\ttrain-merror:0.039864\tval-merror:0.068968\n",
      "[14]\ttrain-merror:0.039728\tval-merror:0.068413\n",
      "[15]\ttrain-merror:0.039558\tval-merror:0.067857\n",
      "[16]\ttrain-merror:0.038912\tval-merror:0.067619\n",
      "[17]\ttrain-merror:0.038776\tval-merror:0.06746\n",
      "[18]\ttrain-merror:0.038333\tval-merror:0.066667\n",
      "[19]\ttrain-merror:0.038197\tval-merror:0.066587\n",
      "[20]\ttrain-merror:0.037687\tval-merror:0.065635\n",
      "[21]\ttrain-merror:0.037075\tval-merror:0.065\n",
      "[22]\ttrain-merror:0.036531\tval-merror:0.064603\n",
      "[23]\ttrain-merror:0.036497\tval-merror:0.064524\n",
      "[24]\ttrain-merror:0.03602\tval-merror:0.064683\n",
      "[25]\ttrain-merror:0.035714\tval-merror:0.064048\n",
      "[26]\ttrain-merror:0.035102\tval-merror:0.063492\n",
      "[27]\ttrain-merror:0.034694\tval-merror:0.063651\n",
      "[28]\ttrain-merror:0.034626\tval-merror:0.062937\n",
      "[29]\ttrain-merror:0.034354\tval-merror:0.063175\n",
      "[30]\ttrain-merror:0.034354\tval-merror:0.06254\n",
      "[31]\ttrain-merror:0.034558\tval-merror:0.062778\n",
      "[32]\ttrain-merror:0.034456\tval-merror:0.06254\n",
      "[33]\ttrain-merror:0.033946\tval-merror:0.062381\n",
      "[34]\ttrain-merror:0.033299\tval-merror:0.061905\n",
      "[35]\ttrain-merror:0.033265\tval-merror:0.061984\n",
      "[36]\ttrain-merror:0.033197\tval-merror:0.061984\n",
      "[37]\ttrain-merror:0.033027\tval-merror:0.062222\n",
      "[38]\ttrain-merror:0.032789\tval-merror:0.061429\n",
      "[39]\ttrain-merror:0.032279\tval-merror:0.061349\n",
      "[40]\ttrain-merror:0.032211\tval-merror:0.060952\n",
      "[41]\ttrain-merror:0.031939\tval-merror:0.060556\n",
      "[42]\ttrain-merror:0.031565\tval-merror:0.060079\n",
      "[43]\ttrain-merror:0.031565\tval-merror:0.060159\n",
      "[44]\ttrain-merror:0.031259\tval-merror:0.059683\n",
      "[45]\ttrain-merror:0.031122\tval-merror:0.059524\n",
      "[46]\ttrain-merror:0.030782\tval-merror:0.060079\n",
      "[47]\ttrain-merror:0.030714\tval-merror:0.060317\n",
      "[48]\ttrain-merror:0.030748\tval-merror:0.059762\n",
      "[49]\ttrain-merror:0.030646\tval-merror:0.059603\n",
      "[50]\ttrain-merror:0.030544\tval-merror:0.059365\n",
      "[51]\ttrain-merror:0.030408\tval-merror:0.058889\n",
      "[52]\ttrain-merror:0.030034\tval-merror:0.05873\n",
      "[53]\ttrain-merror:0.03\tval-merror:0.05881\n",
      "[54]\ttrain-merror:0.029796\tval-merror:0.058571\n",
      "[55]\ttrain-merror:0.029592\tval-merror:0.05873\n",
      "[56]\ttrain-merror:0.029422\tval-merror:0.058571\n",
      "[57]\ttrain-merror:0.029286\tval-merror:0.058254\n",
      "[58]\ttrain-merror:0.029252\tval-merror:0.057937\n",
      "[59]\ttrain-merror:0.02915\tval-merror:0.058413\n",
      "[60]\ttrain-merror:0.028946\tval-merror:0.058095\n",
      "[61]\ttrain-merror:0.028537\tval-merror:0.057698\n",
      "[62]\ttrain-merror:0.028537\tval-merror:0.057778\n",
      "[63]\ttrain-merror:0.028503\tval-merror:0.05754\n",
      "[64]\ttrain-merror:0.028401\tval-merror:0.057381\n",
      "[65]\ttrain-merror:0.028061\tval-merror:0.057302\n",
      "[66]\ttrain-merror:0.028129\tval-merror:0.056905\n",
      "[67]\ttrain-merror:0.027993\tval-merror:0.056587\n",
      "[68]\ttrain-merror:0.027755\tval-merror:0.056746\n",
      "[69]\ttrain-merror:0.027415\tval-merror:0.056667\n",
      "[70]\ttrain-merror:0.027483\tval-merror:0.056984\n",
      "[71]\ttrain-merror:0.027347\tval-merror:0.056349\n",
      "[72]\ttrain-merror:0.027177\tval-merror:0.055476\n",
      "[73]\ttrain-merror:0.027041\tval-merror:0.055317\n",
      "[74]\ttrain-merror:0.027007\tval-merror:0.055714\n",
      "[75]\ttrain-merror:0.026735\tval-merror:0.055476\n",
      "[76]\ttrain-merror:0.026803\tval-merror:0.055397\n",
      "[77]\ttrain-merror:0.026667\tval-merror:0.055476\n",
      "[78]\ttrain-merror:0.026531\tval-merror:0.055238\n",
      "[79]\ttrain-merror:0.026531\tval-merror:0.055159\n",
      "[80]\ttrain-merror:0.026361\tval-merror:0.055476\n",
      "[81]\ttrain-merror:0.026259\tval-merror:0.055238\n",
      "[82]\ttrain-merror:0.025952\tval-merror:0.055317\n",
      "[83]\ttrain-merror:0.025986\tval-merror:0.055159\n",
      "[84]\ttrain-merror:0.025884\tval-merror:0.055\n",
      "[85]\ttrain-merror:0.025646\tval-merror:0.055159\n",
      "[86]\ttrain-merror:0.025442\tval-merror:0.055079\n",
      "[87]\ttrain-merror:0.025476\tval-merror:0.054841\n",
      "[88]\ttrain-merror:0.02534\tval-merror:0.055159\n",
      "[89]\ttrain-merror:0.025374\tval-merror:0.055317\n",
      "[90]\ttrain-merror:0.025238\tval-merror:0.054921\n",
      "[91]\ttrain-merror:0.025204\tval-merror:0.054762\n",
      "[92]\ttrain-merror:0.025136\tval-merror:0.054524\n",
      "[93]\ttrain-merror:0.025034\tval-merror:0.054524\n",
      "[94]\ttrain-merror:0.02483\tval-merror:0.054683\n",
      "[95]\ttrain-merror:0.024762\tval-merror:0.054841\n",
      "[96]\ttrain-merror:0.024694\tval-merror:0.054524\n",
      "[97]\ttrain-merror:0.024592\tval-merror:0.054444\n",
      "[98]\ttrain-merror:0.024524\tval-merror:0.054683\n",
      "[99]\ttrain-merror:0.024456\tval-merror:0.054841\n",
      "[100]\ttrain-merror:0.024558\tval-merror:0.054444\n",
      "[101]\ttrain-merror:0.024422\tval-merror:0.054444\n",
      "[102]\ttrain-merror:0.024388\tval-merror:0.054127\n",
      "[103]\ttrain-merror:0.024252\tval-merror:0.054048\n",
      "[104]\ttrain-merror:0.024116\tval-merror:0.05373\n",
      "[105]\ttrain-merror:0.023946\tval-merror:0.053571\n",
      "[106]\ttrain-merror:0.023844\tval-merror:0.05373\n",
      "[107]\ttrain-merror:0.023741\tval-merror:0.053889\n",
      "[108]\ttrain-merror:0.023776\tval-merror:0.053413\n",
      "[109]\ttrain-merror:0.023707\tval-merror:0.053333\n",
      "[110]\ttrain-merror:0.023571\tval-merror:0.053492\n",
      "[111]\ttrain-merror:0.023333\tval-merror:0.053413\n",
      "[112]\ttrain-merror:0.023095\tval-merror:0.053333\n",
      "[113]\ttrain-merror:0.022959\tval-merror:0.053095\n",
      "[114]\ttrain-merror:0.022925\tval-merror:0.053016\n",
      "[115]\ttrain-merror:0.022789\tval-merror:0.053095\n",
      "[116]\ttrain-merror:0.022687\tval-merror:0.052937\n",
      "[117]\ttrain-merror:0.022687\tval-merror:0.052937\n",
      "[118]\ttrain-merror:0.022619\tval-merror:0.053095\n",
      "[119]\ttrain-merror:0.022517\tval-merror:0.053016\n",
      "[120]\ttrain-merror:0.022483\tval-merror:0.052778\n",
      "[121]\ttrain-merror:0.022415\tval-merror:0.052778\n",
      "[122]\ttrain-merror:0.022347\tval-merror:0.052619\n",
      "[123]\ttrain-merror:0.022177\tval-merror:0.05254\n",
      "[124]\ttrain-merror:0.022177\tval-merror:0.052619\n",
      "[125]\ttrain-merror:0.022109\tval-merror:0.052698\n",
      "[126]\ttrain-merror:0.022075\tval-merror:0.05246\n",
      "[127]\ttrain-merror:0.022041\tval-merror:0.052302\n",
      "[128]\ttrain-merror:0.021973\tval-merror:0.05246\n",
      "[129]\ttrain-merror:0.021905\tval-merror:0.052381\n",
      "[130]\ttrain-merror:0.021837\tval-merror:0.052381\n",
      "[131]\ttrain-merror:0.021837\tval-merror:0.052143\n",
      "[132]\ttrain-merror:0.021735\tval-merror:0.052143\n",
      "[133]\ttrain-merror:0.021769\tval-merror:0.052143\n",
      "[134]\ttrain-merror:0.021803\tval-merror:0.052063\n",
      "[135]\ttrain-merror:0.021701\tval-merror:0.052302\n",
      "[136]\ttrain-merror:0.021531\tval-merror:0.052222\n",
      "[137]\ttrain-merror:0.021429\tval-merror:0.051984\n",
      "[138]\ttrain-merror:0.021429\tval-merror:0.052143\n",
      "[139]\ttrain-merror:0.021259\tval-merror:0.051984\n",
      "[140]\ttrain-merror:0.021156\tval-merror:0.051905\n",
      "[141]\ttrain-merror:0.021122\tval-merror:0.051905\n",
      "[142]\ttrain-merror:0.020986\tval-merror:0.051825\n",
      "[143]\ttrain-merror:0.020918\tval-merror:0.051905\n",
      "[144]\ttrain-merror:0.020918\tval-merror:0.051746\n",
      "[145]\ttrain-merror:0.020782\tval-merror:0.051587\n",
      "[146]\ttrain-merror:0.020816\tval-merror:0.051508\n",
      "[147]\ttrain-merror:0.020714\tval-merror:0.051587\n",
      "[148]\ttrain-merror:0.02068\tval-merror:0.051587\n",
      "[149]\ttrain-merror:0.020646\tval-merror:0.051508\n",
      "[150]\ttrain-merror:0.020544\tval-merror:0.051508\n",
      "[151]\ttrain-merror:0.020442\tval-merror:0.051349\n",
      "[152]\ttrain-merror:0.02034\tval-merror:0.051508\n",
      "[153]\ttrain-merror:0.020408\tval-merror:0.051667\n",
      "[154]\ttrain-merror:0.020408\tval-merror:0.051429\n",
      "[155]\ttrain-merror:0.020238\tval-merror:0.05127\n",
      "[156]\ttrain-merror:0.020136\tval-merror:0.05127\n",
      "[157]\ttrain-merror:0.020034\tval-merror:0.05127\n",
      "[158]\ttrain-merror:0.020068\tval-merror:0.050873\n",
      "[159]\ttrain-merror:0.020034\tval-merror:0.050952\n",
      "[160]\ttrain-merror:0.019898\tval-merror:0.050952\n",
      "[161]\ttrain-merror:0.019966\tval-merror:0.050952\n",
      "[162]\ttrain-merror:0.019864\tval-merror:0.050952\n",
      "[163]\ttrain-merror:0.019932\tval-merror:0.050794\n",
      "[164]\ttrain-merror:0.019898\tval-merror:0.050635\n",
      "[165]\ttrain-merror:0.019762\tval-merror:0.050397\n",
      "[166]\ttrain-merror:0.019694\tval-merror:0.050635\n",
      "[167]\ttrain-merror:0.019728\tval-merror:0.050317\n",
      "[168]\ttrain-merror:0.019626\tval-merror:0.050317\n",
      "[169]\ttrain-merror:0.019558\tval-merror:0.050317\n",
      "[170]\ttrain-merror:0.019456\tval-merror:0.050476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171]\ttrain-merror:0.019354\tval-merror:0.050556\n",
      "[172]\ttrain-merror:0.019252\tval-merror:0.050476\n",
      "[173]\ttrain-merror:0.019218\tval-merror:0.050556\n",
      "[174]\ttrain-merror:0.019082\tval-merror:0.050635\n",
      "[175]\ttrain-merror:0.019014\tval-merror:0.050397\n",
      "[176]\ttrain-merror:0.018946\tval-merror:0.050476\n",
      "[177]\ttrain-merror:0.018844\tval-merror:0.050317\n",
      "[178]\ttrain-merror:0.01881\tval-merror:0.050317\n",
      "[179]\ttrain-merror:0.018878\tval-merror:0.050635\n",
      "[180]\ttrain-merror:0.018571\tval-merror:0.050476\n",
      "[181]\ttrain-merror:0.018537\tval-merror:0.050238\n",
      "[182]\ttrain-merror:0.018469\tval-merror:0.050238\n",
      "[183]\ttrain-merror:0.018503\tval-merror:0.050397\n",
      "[184]\ttrain-merror:0.018401\tval-merror:0.050159\n",
      "[185]\ttrain-merror:0.018435\tval-merror:0.050317\n",
      "[186]\ttrain-merror:0.018333\tval-merror:0.050238\n",
      "[187]\ttrain-merror:0.018299\tval-merror:0.050159\n",
      "[188]\ttrain-merror:0.018197\tval-merror:0.050079\n",
      "[189]\ttrain-merror:0.018197\tval-merror:0.050079\n",
      "[190]\ttrain-merror:0.018163\tval-merror:0.049921\n",
      "[191]\ttrain-merror:0.018163\tval-merror:0.049841\n",
      "[192]\ttrain-merror:0.018129\tval-merror:0.049841\n",
      "[193]\ttrain-merror:0.018095\tval-merror:0.049921\n",
      "[194]\ttrain-merror:0.018095\tval-merror:0.049921\n",
      "[195]\ttrain-merror:0.018061\tval-merror:0.049841\n",
      "[196]\ttrain-merror:0.018027\tval-merror:0.049603\n",
      "[197]\ttrain-merror:0.017959\tval-merror:0.049603\n",
      "[198]\ttrain-merror:0.017823\tval-merror:0.049603\n",
      "[199]\ttrain-merror:0.017857\tval-merror:0.049762\n",
      "[200]\ttrain-merror:0.017721\tval-merror:0.049603\n",
      "[201]\ttrain-merror:0.017721\tval-merror:0.049524\n",
      "[202]\ttrain-merror:0.017755\tval-merror:0.049444\n",
      "[203]\ttrain-merror:0.017585\tval-merror:0.049206\n",
      "[204]\ttrain-merror:0.017551\tval-merror:0.048968\n",
      "[205]\ttrain-merror:0.017585\tval-merror:0.048889\n",
      "[206]\ttrain-merror:0.017449\tval-merror:0.048968\n",
      "[207]\ttrain-merror:0.017381\tval-merror:0.048889\n",
      "[208]\ttrain-merror:0.017347\tval-merror:0.048651\n",
      "[209]\ttrain-merror:0.017347\tval-merror:0.04881\n",
      "[210]\ttrain-merror:0.017313\tval-merror:0.04881\n",
      "[211]\ttrain-merror:0.017313\tval-merror:0.04873\n",
      "[212]\ttrain-merror:0.017313\tval-merror:0.04873\n",
      "[213]\ttrain-merror:0.017211\tval-merror:0.048889\n",
      "[214]\ttrain-merror:0.017143\tval-merror:0.048968\n",
      "[215]\ttrain-merror:0.017143\tval-merror:0.048889\n",
      "[216]\ttrain-merror:0.017041\tval-merror:0.04881\n",
      "[217]\ttrain-merror:0.016973\tval-merror:0.04873\n",
      "[218]\ttrain-merror:0.017041\tval-merror:0.048651\n",
      "[219]\ttrain-merror:0.017007\tval-merror:0.048651\n",
      "[220]\ttrain-merror:0.016905\tval-merror:0.048571\n",
      "[221]\ttrain-merror:0.016837\tval-merror:0.048492\n",
      "[222]\ttrain-merror:0.016735\tval-merror:0.048413\n",
      "[223]\ttrain-merror:0.016735\tval-merror:0.048413\n",
      "[224]\ttrain-merror:0.016667\tval-merror:0.048333\n",
      "[225]\ttrain-merror:0.016599\tval-merror:0.048333\n",
      "[226]\ttrain-merror:0.016531\tval-merror:0.048333\n",
      "[227]\ttrain-merror:0.016531\tval-merror:0.048333\n",
      "[228]\ttrain-merror:0.016463\tval-merror:0.048254\n",
      "[229]\ttrain-merror:0.016497\tval-merror:0.048175\n",
      "[230]\ttrain-merror:0.016293\tval-merror:0.048095\n",
      "[231]\ttrain-merror:0.016293\tval-merror:0.048095\n",
      "[232]\ttrain-merror:0.016224\tval-merror:0.048016\n",
      "[233]\ttrain-merror:0.016156\tval-merror:0.047778\n",
      "[234]\ttrain-merror:0.016122\tval-merror:0.047698\n",
      "[235]\ttrain-merror:0.01602\tval-merror:0.04754\n",
      "[236]\ttrain-merror:0.01602\tval-merror:0.04754\n",
      "[237]\ttrain-merror:0.015918\tval-merror:0.04746\n",
      "[238]\ttrain-merror:0.01585\tval-merror:0.047222\n",
      "[239]\ttrain-merror:0.015816\tval-merror:0.047222\n",
      "[240]\ttrain-merror:0.015816\tval-merror:0.047063\n",
      "[241]\ttrain-merror:0.015748\tval-merror:0.046984\n",
      "[242]\ttrain-merror:0.015646\tval-merror:0.046905\n",
      "[243]\ttrain-merror:0.015646\tval-merror:0.046746\n",
      "[244]\ttrain-merror:0.015612\tval-merror:0.046825\n",
      "[245]\ttrain-merror:0.015578\tval-merror:0.046667\n",
      "[246]\ttrain-merror:0.01551\tval-merror:0.046746\n",
      "[247]\ttrain-merror:0.015306\tval-merror:0.046667\n",
      "[248]\ttrain-merror:0.01534\tval-merror:0.046746\n",
      "[249]\ttrain-merror:0.015374\tval-merror:0.046746\n",
      "[250]\ttrain-merror:0.015238\tval-merror:0.046905\n",
      "[251]\ttrain-merror:0.01517\tval-merror:0.046746\n",
      "[252]\ttrain-merror:0.015068\tval-merror:0.046508\n",
      "[253]\ttrain-merror:0.015068\tval-merror:0.046587\n",
      "[254]\ttrain-merror:0.015034\tval-merror:0.046746\n",
      "[255]\ttrain-merror:0.015\tval-merror:0.046508\n",
      "[256]\ttrain-merror:0.014898\tval-merror:0.046508\n",
      "[257]\ttrain-merror:0.014864\tval-merror:0.046508\n",
      "[258]\ttrain-merror:0.014932\tval-merror:0.046349\n",
      "[259]\ttrain-merror:0.014796\tval-merror:0.046349\n",
      "[260]\ttrain-merror:0.014762\tval-merror:0.046349\n",
      "[261]\ttrain-merror:0.014762\tval-merror:0.046111\n",
      "[262]\ttrain-merror:0.014728\tval-merror:0.046032\n",
      "[263]\ttrain-merror:0.014728\tval-merror:0.046032\n",
      "[264]\ttrain-merror:0.014592\tval-merror:0.046032\n",
      "[265]\ttrain-merror:0.014558\tval-merror:0.045952\n",
      "[266]\ttrain-merror:0.014626\tval-merror:0.045952\n",
      "[267]\ttrain-merror:0.014524\tval-merror:0.045794\n",
      "[268]\ttrain-merror:0.01449\tval-merror:0.045714\n",
      "[269]\ttrain-merror:0.01449\tval-merror:0.045794\n",
      "[270]\ttrain-merror:0.014422\tval-merror:0.045794\n",
      "[271]\ttrain-merror:0.014354\tval-merror:0.045794\n",
      "[272]\ttrain-merror:0.014286\tval-merror:0.045794\n",
      "[273]\ttrain-merror:0.014252\tval-merror:0.045476\n",
      "[274]\ttrain-merror:0.014218\tval-merror:0.045635\n",
      "[275]\ttrain-merror:0.014116\tval-merror:0.045556\n",
      "[276]\ttrain-merror:0.014116\tval-merror:0.045714\n",
      "[277]\ttrain-merror:0.014048\tval-merror:0.045873\n",
      "[278]\ttrain-merror:0.013946\tval-merror:0.045635\n",
      "[279]\ttrain-merror:0.013912\tval-merror:0.045635\n",
      "[280]\ttrain-merror:0.013946\tval-merror:0.045635\n",
      "[281]\ttrain-merror:0.013946\tval-merror:0.045635\n",
      "[282]\ttrain-merror:0.013912\tval-merror:0.045635\n",
      "[283]\ttrain-merror:0.013878\tval-merror:0.045635\n",
      "[284]\ttrain-merror:0.013776\tval-merror:0.045397\n",
      "[285]\ttrain-merror:0.013741\tval-merror:0.045397\n",
      "[286]\ttrain-merror:0.013673\tval-merror:0.045317\n",
      "[287]\ttrain-merror:0.013639\tval-merror:0.045238\n",
      "[288]\ttrain-merror:0.013605\tval-merror:0.045238\n",
      "[289]\ttrain-merror:0.013537\tval-merror:0.045317\n",
      "[290]\ttrain-merror:0.013469\tval-merror:0.045079\n",
      "[291]\ttrain-merror:0.013367\tval-merror:0.045238\n",
      "[292]\ttrain-merror:0.013299\tval-merror:0.044921\n",
      "[293]\ttrain-merror:0.013333\tval-merror:0.044841\n",
      "[294]\ttrain-merror:0.013333\tval-merror:0.044841\n",
      "[295]\ttrain-merror:0.013333\tval-merror:0.044841\n",
      "[296]\ttrain-merror:0.013367\tval-merror:0.044921\n",
      "[297]\ttrain-merror:0.013333\tval-merror:0.044762\n",
      "[298]\ttrain-merror:0.013231\tval-merror:0.044841\n",
      "[299]\ttrain-merror:0.013129\tval-merror:0.044841\n",
      "[300]\ttrain-merror:0.013129\tval-merror:0.045\n",
      "[301]\ttrain-merror:0.013163\tval-merror:0.044921\n",
      "[302]\ttrain-merror:0.013095\tval-merror:0.045079\n",
      "[303]\ttrain-merror:0.012993\tval-merror:0.045079\n",
      "[304]\ttrain-merror:0.012959\tval-merror:0.045079\n",
      "[305]\ttrain-merror:0.012959\tval-merror:0.045\n",
      "[306]\ttrain-merror:0.012857\tval-merror:0.045\n",
      "[307]\ttrain-merror:0.012857\tval-merror:0.045\n",
      "[308]\ttrain-merror:0.012789\tval-merror:0.045079\n",
      "[309]\ttrain-merror:0.012755\tval-merror:0.045079\n",
      "[310]\ttrain-merror:0.012755\tval-merror:0.044841\n",
      "[311]\ttrain-merror:0.012619\tval-merror:0.045\n",
      "[312]\ttrain-merror:0.012653\tval-merror:0.044921\n",
      "[313]\ttrain-merror:0.012653\tval-merror:0.045\n",
      "[314]\ttrain-merror:0.012585\tval-merror:0.045079\n",
      "[315]\ttrain-merror:0.012585\tval-merror:0.045079\n",
      "[316]\ttrain-merror:0.012517\tval-merror:0.044921\n",
      "[317]\ttrain-merror:0.012483\tval-merror:0.044762\n",
      "[318]\ttrain-merror:0.012449\tval-merror:0.044762\n",
      "[319]\ttrain-merror:0.012415\tval-merror:0.044762\n",
      "[320]\ttrain-merror:0.012347\tval-merror:0.044683\n",
      "[321]\ttrain-merror:0.012347\tval-merror:0.044841\n",
      "[322]\ttrain-merror:0.012245\tval-merror:0.044841\n",
      "[323]\ttrain-merror:0.012211\tval-merror:0.044603\n",
      "[324]\ttrain-merror:0.012177\tval-merror:0.044683\n",
      "[325]\ttrain-merror:0.012143\tval-merror:0.044524\n",
      "[326]\ttrain-merror:0.012143\tval-merror:0.044762\n",
      "[327]\ttrain-merror:0.012109\tval-merror:0.044603\n",
      "[328]\ttrain-merror:0.012109\tval-merror:0.044603\n",
      "[329]\ttrain-merror:0.012041\tval-merror:0.044524\n",
      "[330]\ttrain-merror:0.012075\tval-merror:0.044444\n",
      "[331]\ttrain-merror:0.012007\tval-merror:0.044365\n",
      "[332]\ttrain-merror:0.011939\tval-merror:0.044286\n",
      "[333]\ttrain-merror:0.011803\tval-merror:0.044206\n",
      "[334]\ttrain-merror:0.011735\tval-merror:0.044048\n",
      "[335]\ttrain-merror:0.011701\tval-merror:0.044048\n",
      "[336]\ttrain-merror:0.011701\tval-merror:0.043889\n",
      "[337]\ttrain-merror:0.011667\tval-merror:0.044048\n",
      "[338]\ttrain-merror:0.011667\tval-merror:0.044048\n",
      "[339]\ttrain-merror:0.011565\tval-merror:0.044048\n",
      "[340]\ttrain-merror:0.011565\tval-merror:0.043889\n",
      "[341]\ttrain-merror:0.011599\tval-merror:0.043889\n",
      "[342]\ttrain-merror:0.011531\tval-merror:0.04381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[343]\ttrain-merror:0.011463\tval-merror:0.04381\n",
      "[344]\ttrain-merror:0.011463\tval-merror:0.04373\n",
      "[345]\ttrain-merror:0.011361\tval-merror:0.043651\n",
      "[346]\ttrain-merror:0.011361\tval-merror:0.043651\n",
      "[347]\ttrain-merror:0.011293\tval-merror:0.043571\n",
      "[348]\ttrain-merror:0.011259\tval-merror:0.043492\n",
      "[349]\ttrain-merror:0.011293\tval-merror:0.043413\n",
      "[350]\ttrain-merror:0.011224\tval-merror:0.043413\n",
      "[351]\ttrain-merror:0.01119\tval-merror:0.043571\n",
      "[352]\ttrain-merror:0.011156\tval-merror:0.043413\n",
      "[353]\ttrain-merror:0.011122\tval-merror:0.043333\n",
      "[354]\ttrain-merror:0.011156\tval-merror:0.043333\n",
      "[355]\ttrain-merror:0.011156\tval-merror:0.043333\n",
      "[356]\ttrain-merror:0.011122\tval-merror:0.043254\n",
      "[357]\ttrain-merror:0.01102\tval-merror:0.043254\n",
      "[358]\ttrain-merror:0.010918\tval-merror:0.043333\n",
      "[359]\ttrain-merror:0.010816\tval-merror:0.043333\n",
      "[360]\ttrain-merror:0.010816\tval-merror:0.043254\n",
      "[361]\ttrain-merror:0.010816\tval-merror:0.043254\n",
      "[362]\ttrain-merror:0.010782\tval-merror:0.043175\n",
      "[363]\ttrain-merror:0.01068\tval-merror:0.043175\n",
      "[364]\ttrain-merror:0.010646\tval-merror:0.043175\n",
      "[365]\ttrain-merror:0.010646\tval-merror:0.043095\n",
      "[366]\ttrain-merror:0.010646\tval-merror:0.043095\n",
      "[367]\ttrain-merror:0.010612\tval-merror:0.043095\n",
      "[368]\ttrain-merror:0.010476\tval-merror:0.042937\n",
      "[369]\ttrain-merror:0.010476\tval-merror:0.042937\n",
      "[370]\ttrain-merror:0.010306\tval-merror:0.042937\n",
      "[371]\ttrain-merror:0.010306\tval-merror:0.042857\n",
      "[372]\ttrain-merror:0.010272\tval-merror:0.042857\n",
      "[373]\ttrain-merror:0.010204\tval-merror:0.042857\n",
      "[374]\ttrain-merror:0.01017\tval-merror:0.042857\n",
      "[375]\ttrain-merror:0.010102\tval-merror:0.042778\n",
      "[376]\ttrain-merror:0.010136\tval-merror:0.042778\n",
      "[377]\ttrain-merror:0.010102\tval-merror:0.042857\n",
      "[378]\ttrain-merror:0.010068\tval-merror:0.042857\n",
      "[379]\ttrain-merror:0.010034\tval-merror:0.042778\n",
      "[380]\ttrain-merror:0.01\tval-merror:0.042619\n",
      "[381]\ttrain-merror:0.01\tval-merror:0.042619\n",
      "[382]\ttrain-merror:0.009966\tval-merror:0.042698\n",
      "[383]\ttrain-merror:0.009932\tval-merror:0.042619\n",
      "[384]\ttrain-merror:0.009898\tval-merror:0.042619\n",
      "[385]\ttrain-merror:0.009864\tval-merror:0.04254\n",
      "[386]\ttrain-merror:0.009864\tval-merror:0.04254\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'booster':'gbtree',\n",
    "'objective': 'multi:softmax', #多分类的问题\n",
    "'num_class':10, # 类别数，与 multisoftmax 并用\n",
    "'gamma':0.1,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "'max_depth':12, # 构建树的深度，越大越容易过拟合\n",
    "'lambda':2,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "'subsample':0.7, # 随机采样训练样本\n",
    "'colsample_bytree':0.7, # 生成树时进行的列采样\n",
    "'min_child_weight':3, \n",
    "# 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "'eta': 0.007, # 如同学习率\n",
    "'seed':1000,\n",
    "'nthread':7,# cpu 线程数\n",
    "#'eval_metric': 'auc'\n",
    "}\n",
    "plst = list(params.items())\n",
    "num_rounds = 5000\n",
    "watchlist = [(xgb_train, 'train'), (xgb_val, 'val')]\n",
    "\n",
    "model = xgb.train(plst, xgb_train, num_rounds, watchlist,early_stopping_rounds=100)\n",
    "model.save_model('./model/xgb.model')\n",
    "print(\"best best_ntree_limit\", model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb_test, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "np.savetxt('xgb_submission.csv', np.c_[range(1,len(tests)+1),preds],delimiter=',',header='ImageId,Label',comments='',fmt='%d')\n",
    "\n",
    "cost_time = time.time()-start_time\n",
    "print(\"xgboost success!\",'\\n',\"cost time:\",cost_time,\"(s)......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost by others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xy, val = train_test_split(train, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "29633      1       0       0       0       0       0       0       0       0   \n",
      "345        5       0       0       0       0       0       0       0       0   \n",
      "36369      2       0       0       0       0       0       0       0       0   \n",
      "16624      8       0       0       0       0       0       0       0       0   \n",
      "14389      4       0       0       0       0       0       0       0       0   \n",
      "\n",
      "       pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "29633       0    ...            0         0         0         0         0   \n",
      "345         0    ...            0         0         0         0         0   \n",
      "36369       0    ...            0         0         0         0         0   \n",
      "16624       0    ...            0         0         0         0         0   \n",
      "14389       0    ...            0         0         0         0         0   \n",
      "\n",
      "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "29633         0         0         0         0         0  \n",
      "345           0         0         0         0         0  \n",
      "36369         0         0         0         0         0  \n",
      "16624         0         0         0         0         0  \n",
      "14389         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.values.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n",
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "X_train=X_train.values.reshape(42000,28,28,1)\n",
    "X_test=X_test.values.reshape(28000,28,28,1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "Y_train=convert_to_one_hot(Y_train,10).T\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32,[None,n_H0,n_W0,n_C0],name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32,[None,n_y],name=\"Y\")\n",
    "\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    W1 = tf.get_variable(\"W1\",[4,4,1,8],initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\",[2,2,8,16],initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    \n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1,ksize=[1,8,8,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    Z2 = tf.nn.conv2d(P1,W2,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2,ksize=[1,4,4,1],strides=[1,4,4,1],padding=\"SAME\")\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2,10,activation_fn=None)\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3,Y):\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3,labels=Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train,X_test, learning_rate = 0.005,\n",
    "          num_epochs = 150, minibatch_size = 64, print_cost = True):\n",
    "     \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []\n",
    "    X, Y = create_placeholders(n_H0,n_W0,n_C0,n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    cost =compute_cost(Z3,Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        parameters = sess.run(parameters)\n",
    "        correct_predictions = tf.equal(tf.argmax(Y, axis=1), tf.argmax(Z3, axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, 'float'))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        Y_test = sess.run(tf.argmax(Z3, 1), feed_dict={X: X_test})\n",
    "\n",
    "        return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.275007\n",
      "Cost after epoch 5: 0.055590\n",
      "Cost after epoch 10: 0.045429\n",
      "Cost after epoch 15: 0.036315\n",
      "Cost after epoch 20: 0.037503\n",
      "Cost after epoch 25: 0.033304\n",
      "Cost after epoch 30: 0.030069\n",
      "Cost after epoch 35: 0.029746\n",
      "Cost after epoch 40: 0.027328\n",
      "Cost after epoch 45: 0.023945\n",
      "Cost after epoch 50: 0.025601\n",
      "Cost after epoch 55: 0.028416\n",
      "Cost after epoch 60: 0.026039\n",
      "Cost after epoch 65: 0.027872\n",
      "Cost after epoch 70: 0.022534\n",
      "Cost after epoch 75: 0.022599\n",
      "Cost after epoch 80: 0.029183\n",
      "Cost after epoch 85: 0.024307\n",
      "Cost after epoch 90: 0.029069\n",
      "Cost after epoch 95: 0.024801\n",
      "Cost after epoch 100: 0.025686\n",
      "Cost after epoch 105: 0.023529\n",
      "Cost after epoch 110: 0.026386\n",
      "Cost after epoch 115: 0.032709\n",
      "Cost after epoch 120: 0.023088\n",
      "Cost after epoch 125: 0.026099\n",
      "Cost after epoch 130: 0.019448\n",
      "Cost after epoch 135: 0.021558\n",
      "Cost after epoch 140: 0.029056\n",
      "Cost after epoch 145: 0.021231\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XeYVNX9x/H3d2dZemeX3juigtKMDcSCRsUYjWiMRk1s0Whiiv6MmmhM0ZhoYsMYW2I3RlGxIFJsICBNeoel7S5lKcv27++PexeHZWZnUYZZ5PN6nnl25rY5c3f3fuacc++55u6IiIhUJS3VBRARkZpPYSEiIgkpLEREJCGFhYiIJKSwEBGRhBQWIiKSkMJCDilm9raZXZrqcogcbBQWckCY2UozOznV5XD309396VSXA8DMJprZjw7A+9Q2syfMbJuZbTCznydY/mfhcvnherWj5nUyswlmVmBmC6N/p2b2QzMrM7MdUY+hSfxocgApLOQbw8zSU12GCjWpLMBvge5AR2AY8CszGxFrQTM7DbgZGA50AroAv4ta5HlgJtAcuBV4xcwyo+Z/6u4Noh4T9+9HkVRRWEjKmdmZZjbLzLaa2SdmdkTUvJvNbJmZbTez+Wb2nah5PzSzj83sb2a2GfhtOO0jM/uLmW0xsxVmdnrUOru/zVdj2c5mNjl87/fN7CEz+0+czzDUzLLN7NdmtgF40syamtmbZpYbbv9NM2sXLn83cDzwYPgN/MFwei8zG2dmm81skZl9bz/s4kuAu9x9i7svAP4J/DDOspcC/3L3ee6+BbirYlkz6wEcBdzh7rvc/b/AXOC7+6GMUsMpLCSlzOwo4AngKoJvq6OBMVFNH8sIDqqNCb7h/sfMWkdtYjCwHMgC7o6atghoAdwD/MvMLE4Rqlr2OeCzsFy/BX6Q4OO0ApoRfIO/kuD/68nwdQdgF/AggLvfCnwIXBd+A7/OzOoD48L3zQIuBB42s8NivZmZPRwGbKzHnHCZpkAbYHbUqrOBmNsMp1detqWZNQ/nLXf37VVsq7+Z5ZnZYjO7rYbVsORrUFhIqv0YGO3uU929LOxPKAKGALj7y+6+zt3L3f1FYAkwKGr9de7+D3cvdfdd4bRV7v5Pdy8DngZaAy3jvH/MZc2sAzAQuN3di939I2BMgs9STvCtuyj85r3J3f/r7gXhAfZu4MQq1j8TWOnuT4af53Pgv8B5sRZ292vdvUmcR0XtrEH4Mz9q1XygYZwyNIixLOHyledV3tZkoC9B0H2XIOx+WcXnlYOIwkJSrSNwU/S3YqA9wbdhzOySqCaqrQQHoxZR66+Jsc0NFU/cvSB82iDGclUt2wbYHDUt3ntFy3X3wooXZlbPzEab2Soz20ZwMG1iZpE463cEBlfaF98nqLF8VTvCn42ipjUCtsdYtmL5yssSLl953h7bcvfl7r4iDPa5wJ3ECTo5+CgsJNXWAHdX+lZcz92fN7OOBO3r1wHN3b0J8AUQ3aSUrGGT1wPNzKxe1LT2CdapXJabgJ7AYHdvBJwQTrc4y68BJlXaFw3c/ZpYb2Zmj1Y68yj6MQ8g7HdYDxwZteqRwLw4n2FejGU3uvumcF4XM2tYaX68bTl7/q7kIKawkAOplpnViXqkE4TB1WY22AL1zezb4QGpPsEBJxfAzC4jqFkknbuvAqYTdJpnmNkxwFn7uJmGBP0UW82sGXBHpfkbCc42qvAm0MPMfmBmtcLHQDPrHaeMV1c68yj6Ed2P8Azwm7DDvRdB099Tccr8DHCFmfUJ+zt+U7Gsuy8GZgF3hL+/7wBHEDSVYWanm1nL8Hkv4Dbg9WrsJzkIKCzkQBpLcPCsePzW3acTHLweBLYASwnPvnH3+cB9wKcEB9bDgY8PYHm/DxwDbAJ+D7xI0J9SXfcDdYE8YArwTqX5DwDnhWdK/T3s1zgVGAWsI2gi+zNQm6/nDoITBVYBk4B73f0dADPrENZEOgCE0+8BJoTLr2LPkBsFDCD4Xf0JOM/dc8N5w4E5ZraT4Hf9KvCHr1l2qSFMNz8SqR4zexFY6O6Vawgi33iqWYjEETYBdTWzNAsuYhsJvJbqcomkgs6BFomvFUFTSnMgG7jG3WemtkgiqaFmKBERSUjNUCIiktA3phmqRYsW3qlTp1QXQ0TkoDJjxow8d89MtNw3Jiw6derE9OnTU10MEZGDipmtqs5yaoYSEZGEFBYiIpKQwkJERBJSWIiISEIKCxERSUhhISIiCSksREQkoUM+LHYWlfLX9xYxa83WVBdFRKTGOuTDorCkjL9/sJQ52QoLEZF4DvmwSE8LdkFpmQZUFBGJ55APizArKCtXWIiIxHPIh8XumoXCQkQkrkM+LCJpBkC57ushIhLXIR8W6WFYqM9CRCS+Qz4s0sKwKCsvT3FJRERqrkM+LCCoXZSpGUpEJC6FBUG/hTq4RUTiU1gQhEWZ+ixEROJSWBCGhZqhRETiUlgQ9lmoGUpEJC6FBeqzEBFJRGFBEBblCgsRkbgUFgRDfqhmISISn8KCYDBB9VmIiMSX1LAwsxFmtsjMlprZzTHm/9zM5pvZHDMbb2Ydo+aVmdms8DEmmeVUzUJEpGrpydqwmUWAh4BTgGxgmpmNcff5UYvNBAa4e4GZXQPcA1wQztvl7v2SVb5o6rMQEalaMmsWg4Cl7r7c3YuBF4CR0Qu4+wR3LwhfTgHaJbE8caWnGaUaG0pEJK5khkVbYE3U6+xwWjxXAG9Hva5jZtPNbIqZnRNrBTO7Mlxmem5u7lcuaJrpOgsRkaokrRkKsBjTYh6RzexiYABwYtTkDu6+zsy6AB+Y2Vx3X7bHxtwfAx4DGDBgwFc+2qdHFBYiIlVJZs0iG2gf9bodsK7yQmZ2MnArcLa7F1VMd/d14c/lwESgf7IKqovyRESqlsywmAZ0N7POZpYBjAL2OKvJzPoDowmCIidqelMzqx0+bwEcC0R3jO9XETVDiYhUKWnNUO5eambXAe8CEeAJd59nZncC0919DHAv0AB42cwAVrv72UBvYLSZlRME2p8qnUW1X0U0NpSISJWS2WeBu48FxlaadnvU85PjrPcJcHgyyxYtPWIUlehsKBGReHQFN8HZUOqzEBGJT2GBhigXEUlEYQFE0tIUFiIiVVBYoJqFiEgiCgsqrrNQB7eISDwKC8KBBFWxEBGJS2GBBhIUEUlEYQGkpRllZapaiIjEo7Ag7OB2hYWISDwKCzTch4hIIgoLNOqsiEgiCgvCmoX6LERE4lJYoD4LEZFEFBYEw32oGUpEJD6FBRBJQx3cIiJVUFjw5UCCrqYoEZGYFBYEfRaAhvwQEYlDYUFwNhSgIT9EROJQWPBlWCgrRERiU1jwZTOUahYiIrEpLAjuwQ06I0pEJB6FBZAeqahZKCxERGJRWBDdZ6GwEBGJRWFBdJ+FwkJEJBaFBeqzEBFJRGHBl30WCgsRkdgUFgTDfYCaoURE4lFYABE1Q4mIVElhwZdnQyksRERiU1jw5dlQCgsRkdiSGhZmNsLMFpnZUjO7Ocb8n5vZfDObY2bjzaxj1LxLzWxJ+Lg0meXUQIIiIlVLWliYWQR4CDgd6ANcaGZ9Ki02Exjg7kcArwD3hOs2A+4ABgODgDvMrGmyyqpmKBGRqiWzZjEIWOruy929GHgBGBm9gLtPcPeC8OUUoF34/DRgnLtvdvctwDhgRLIKqmYoEZGqJTMs2gJrol5nh9PiuQJ4e1/WNbMrzWy6mU3Pzc39ygVVzUJEpGrJDAuLMS3m0djMLgYGAPfuy7ru/pi7D3D3AZmZmV+5oBEN9yEiUqVkhkU20D7qdTtgXeWFzOxk4FbgbHcv2pd195fdNQvdg1tEJKZkhsU0oLuZdTazDGAUMCZ6ATPrD4wmCIqcqFnvAqeaWdOwY/vUcFpSpIdXcJeVKSxERGJJT9aG3b3UzK4jOMhHgCfcfZ6Z3QlMd/cxBM1ODYCXLbiKerW7n+3um83sLoLAAbjT3Tcnq6xhVqgZSkQkjqSFBYC7jwXGVpp2e9Tzk6tY9wngieSV7ksVNYtyNUOJiMSkK7hRB7eISCIKC6JPndUV3CIisSgsiLpTnjq4RURiUlgQdQ9u9VmIiMSksEB9FiIiiSgs0HAfIiKJKCzQQIIiIokoLFDNQkQkEYUF6rMQEUlEYYFqFiIiiSgsiBpIUGEhIhKTwgIIKxZqhhIRiUNhAZgZkTTTcB8iInEoLEJBWKS6FCIiNZPCIhQx1SxEROJRWITS00x9FiIicSgsQpGIUa6wEBGJSWERUs1CRCQ+hUUozUzXWYiIxKGwCKWnKSxEROJRWIQiEYWFiEg8CotQxNRnISISj8IiFFEzlIhIXAqLUHpamsJCRCQOhUUoTafOiojEpbAIpWsgQRGRuBQWoUiaUaaKhYhITNUKCzM7vzrTDmaqWYiIxFfdmsUt1Zx20EpLM0pVtRARiSm9qplmdjpwBtDWzP4eNasRUJpo42Y2AngAiACPu/ufKs0/AbgfOAIY5e6vRM0rA+aGL1e7+9mJP85Xl55mlOiGFiIiMVUZFsA6YDpwNjAjavp24GdVrWhmEeAh4BQgG5hmZmPcfX7UYquBHwK/iLGJXe7eL0H59ptImrGrRDULEZFYqgwLd58NzDaz59y9BMDMmgLt3X1Lgm0PApa6+/JwvReAkcDusHD3leG8lH+l10V5IiLxVbfPYpyZNTKzZsBs4Ekz+2uCddoCa6JeZ4fTqquOmU03sylmdk6sBczsynCZ6bm5ufuw6b2lq89CRCSu6oZFY3ffBpwLPOnuRwMnJ1jHYkzbl6NxB3cfAFwE3G9mXffamPtj7j7A3QdkZmbuw6b3Fkkzyl1hISISS3XDIt3MWgPfA96s5jrZQPuo1+0I+kCqxd3XhT+XAxOB/tVd96uI6ApuEZG4qhsWdwLvAsvcfZqZdQGWJFhnGtDdzDqbWQYwChhTnTczs6ZmVjt83gI4lqi+jmSIaGwoEZG4Ep0NBYC7vwy8HPV6OfDdBOuUmtl1BCETAZ5w93lmdicw3d3HmNlA4H9AU+AsM/udux8G9AZGhx3facCfKp1Ftd/p5kciIvFVKyzMrB3wD4Jv+A58BNzg7tlVrefuY4GxlabdHvV8GkHzVOX1PgEOr07Z9hedDSUiEl91m6GeJGhCakNwRtMb4bRvjODmRyk/g1dEpEaqblhkuvuT7l4aPp4Cvt7pRzVMcFvVVJdCRKRmqm5Y5JnZxWYWCR8XA5uSWbADTQMJiojEV92wuJzgtNkNwHrgPOCyZBUqFdJ0D24Rkbiq1cEN3AVcWjHER3gl918IQuQbQWdDiYjEV92axRHRY0G5+2aSfJHcgRb0WSgsRERiqW5YpIUDCAK7axbVrZUcFCKmsBARiae6B/z7gE/M7BWC6yy+B9ydtFKlQLqG+xARiau6V3A/Y2bTgZMIBgg8N9lXVB9okbSgklVe7qSlxRoDUUTk0FXtpqQwHL5RAREtEjbIlZY7GQoLEZE9VLfP4huvomahfgsRkb0pLELpYW2iTPe0EBHZi8IiFKkIC90tT0RkLwqLUEVYaDBBEZG9KSxCu2sW6rMQEdmLwiKkPgsRkfgUFqGKaytK1WchIrIXhUUoXc1QIiJxKSxCETVDiYjEpbAIqYNbRCQ+hUUoXX0WIiJxKSxCuwcSVDOUiMheFBah3TULNUOJiOxFYRFK291noSu4RUQqU1iE1GchIhKfwiKkU2dFROJTWIR06qyISHwKi1BEHdwiInEpLEIVfRblCgsRkb0oLEJpppqFiEg8SQ0LMxthZovMbKmZ3Rxj/glm9rmZlZrZeZXmXWpmS8LHpcksJ0B6RH0WIiLxJC0szCwCPAScDvQBLjSzPpUWWw38EHiu0rrNgDuAwcAg4A4za5qssoJGnRURqUoyaxaDgKXuvtzdi4EXgJHRC7j7SnefA1S+Eu40YJy7b3b3LcA4YEQSy7p7uA+FhYjI3pIZFm2BNVGvs8Np+21dM7vSzKab2fTc3NyvXFCAiPosRETiSmZYWIxp1T0SV2tdd3/M3Qe4+4DMzMx9KlxlkYiG+xARiSeZYZENtI963Q5YdwDW/Uq+7LNI5ruIiByckhkW04DuZtbZzDKAUcCYaq77LnCqmTUNO7ZPDaclTcWps6pZiIjsLWlh4e6lwHUEB/kFwEvuPs/M7jSzswHMbKCZZQPnA6PNbF647mbgLoLAmQbcGU5LGg1RLiISX3oyN+7uY4GxlabdHvV8GkETU6x1nwCeSGb5okV0nYWISFy6gjtUUbMoVqeFiMheFBahurUiNKqTTvaWXakuiohIjaOwCJkZ3bIasDRnR6qLIiJS4ygsonTLasAyhYWIyF4UFlG6ZTVg085ituwsTnVRRERqFIVFlG5ZDQBYmqvahYhINIVFlG6ZDQHUbyEiUonCIkrbpnWpnZ6msBARqURhESWSZnTJbMAyNUOJiOxBYVGJTp8VEdmbwqKSbpkNWLt1F7uKy1JdFBGRGkNhUUm3rAa4o6YoEZEoCotKKk6fVViIiHxJYVFJpxb1iKQZCzdsT3VRRERqDIVFJbXTI/Ru3ZDZa7amuigiIjWGwiKG/u2bMnvNVt3bQkQkpLCIoX+HJuwsLtMptCIiIYVFDP07NAVg5uotKS6JiEjNoLCIoVPzejSpV4uZq9VvISICCouYzIx+7Zswc41qFiIioLCIq3/7pizJ2cG2wpJUF0VEJOUUFnH079AEd5izJj/VRRERSTmFRRxHtm8CwL8+Ws6G/MIUl0ZEJLUUFnE0rluLm07pwUdL8zjx3gmMmb0u1UUSEUkZhUUVrh/enQ9uGkqPlg256835FJZoJFoROTQpLBJo36wet5zRi9ztRbw4bU2qiyMikhIKi2o4pktzBnZqyiMTl1FUqtqFiBx6FBbVYGb8dHh3Nmwr5JlPVqW6OCIiB5zCopqO69aCE3pkcvfYBfxx7AJKy8pTXSQRkQMmqWFhZiPMbJGZLTWzm2PMr21mL4bzp5pZp3B6JzPbZWazwsejySxndZgZj18ygIuHdGD05OXc9voXqS6SiMgBk56sDZtZBHgIOAXIBqaZ2Rh3nx+12BXAFnfvZmajgD8DF4Tzlrl7v2SV76vISE/j9+ccTnpaGs98upKrTuhKpxb1U10sEZGkS2bNYhCw1N2Xu3sx8AIwstIyI4Gnw+evAMPNzJJYpv3i2qFdqRVJ4+GJS1NdFBGRAyKZYdEWiD7XNDucFnMZdy8F8oHm4bzOZjbTzCaZ2fGx3sDMrjSz6WY2PTc3d/+WvgpZjepw4aAOvPr5Wlbm7WRudj6524sO2PuLiBxoSWuGAmLVECrfei7eMuuBDu6+ycyOBl4zs8PcfdseC7o/BjwGMGDAgAN6W7urTuzCc1NXM+y+ibgHV3w/+6PB9G3b+EAWQ0TkgEhmzSIbaB/1uh1QecyM3cuYWTrQGNjs7kXuvgnA3WcAy4AeSSzrPmvduC53jjyMS4Z05N7zjqBB7XS+//hUpizfRLluxyoi3zDJrFlMA7qbWWdgLTAKuKjSMmOAS4FPgfOAD9zdzSyTIDTKzKwL0B1YnsSyfiWjBnXY/XxIl+aMemwKox6bQsM66Qzq1IyTemdx2mGtaNGgdgpLKSLy9SUtLNy91MyuA94FIsAT7j7PzO4Eprv7GOBfwL/NbCmwmSBQAE4A7jSzUqAMuNrdNyerrPtD+2b1ePP645iwKIfpq7bw4ZJcxi/M4R/jlzL+phOpXzuZuSwiklzm/s1oMhkwYIBPnz491cXYzd2ZvCSPS5/4jJtO6cH1w7unukgiInsxsxnuPiDRcrqCO0nMjBN7ZHLaYS0ZPXk5m3bobCkROXipbSTJfnlaT8bNn8yv/zuX3q0bUqdWhIsHd6RxvVqpLpqISLUpLJKsW1ZDLhzUgWenruaDhRspd3h00jKuG9aNHx/fhbS0Gn8NooiImqEOhDtH9mXarSez5O4zePuG4xnYqRl/fHshV/9nBgXFpXstvzx3B3e/NZ+8sOkqe0sBvx0zb/drEZEDTR3cKeDuPPnxSn7/1nw6t6jP6X1bM7BzM47u2JSlOTu4/KlpbN5ZTJfM+vz+nL784qXZrMsv5NJjOvK7kX1TXXwRSYF3vlhPZsM6HN2x6X7dbnU7uBUWKTRhUQ5/G7eYeeu2UVbupBmkp6XRsnFtfn5KD25/bR7bi0ppVj+Dvm0bM2X5Jj781TBaNqoDQGFJGS9OW8MZh7cms6Gu5RD5JtlaUEy9jHQy0tNwd466axydW9Tn1WuP3a/vU92wUJ9FCg3rmcWwnlnsKCpl5uotTFuxmbydxdw4vDtZjerQPashD09cys9O7kGdWhGG/mUij0xcxm/PPoy8HUVc+cx0Pl+9lY+X5vHYJcHv+o3Z65i+cjNrtxZydr82nH1kmxR/SpFvnlWbdvLmnPVcc2LXpPQ7lpaVc+rfJvPdo9vx6xG9yNlexJaCEvLXbCW/oCQlJ8goLGqABrXTOb57Jsd3z9xjet+2jXn4+0fvfn1u/7Y8/9lq1m3dxeert7KjqIRT+7Tkvfkb+WhJHsvzdnD76/NoWDudBnXSeX/BRlbl7eS6k7pxEAzmK1Kl9fm7OPfhT3jwov4c3bFZUt/r5elrmJOdz13nxG72fWzycp6duppuWQ047bBW+/39Z2dvJWd7EVOXbwJg4YbtAJQ7fLwsjzMOb73f3zMRhcVB5PqTuvPp8k2s3LSTfu2b8NPh3ejRsiGn/G0Sv3xlNjnbizi5dxajfzCAsnLn5lfncN+4xbw7fwMn9WrJsJ6ZHNGuCZE0w92Zk53PG7PXsXF7EQ3rpDO4czPOPrJNlcEyaXEuz09dze+/03e/DGOSs72QCx+bwg+GdOSHx3b+2tuTg0dpWTkbtxfRtkndai0/bv5G1ucX8uK0NfscFm/NWc/6/F0c2b4J/do3oVYk/rk97s6DE5ayalMB1wztSptK5XN3PliYA8BDE5Zyap+W+/3L2KTFeQDMW7eN0rJyFq4PxlCtlxFh0qJchYVUrUPzenz065P2mn7rGX24+j8z6NWqIfeP6k8kzYikGfedfyT92jfh9VnrePCDJfx9/BKa1c+gWf0McrYVsq2wlIxIGm2b1mVrQTHPTV3N+wty+N6Adrw+ax1LcnZQt1Yagzs358aTgyvQ/zh2AQs3bGdJznae/dEQWjWuE7Os7s7UFZsZM3sd89dt46ZTe+xVcwL463uLWZa7k9+9OZ9Wjesyou/+/5Z2MNm8s5hdJWXVPoBWx8Zthbv7uSrbXljCyAc/5uen9uDMI5LTZPnmnHV8sDCHv35vz3uZPfPpKu4eu4CXrz6Gozo0Zc3mAu5/fwnZWwooKSvnsUsG7PGFZOKi4DYE783fyN1l5WzbVcL3Rn/KLaf35uQ+LeO+/7bCEn720iyKS4NbIQ/vlcXjlw7Y4wA/YVEOu4rLOOPw1nyxdhurNhUA8P6CjVxyTKc9tjdv3TbW5xcyqHMzPluxmclL8jixx95/24nkbC+kef3aRGI0Y01enEuaQVFpOYs37mDhhu20alSH/h2aMHlJLu5+wFsLdOrsN8Bph7XkoYuO4pkrBtEgagwqM+OSYzrx32u+xYzfnMIDo/oxtGcmPVo24Jz+bbnnu0cw7TcnM+EXQ5nxm1P45Wk9GTt3PT/412e888UGGtZOZ9uuUh4Yv4SJi3L5dPkmFm7YzkWDO7BxWxHfefhjXvhsNUWlZXuUx925591FjHpsCv/7fC052wq5/KlpvDVn/R7LLdywjZemr+GiwR3o174JN7wwk/Mf/YRv/XE8j39Y/XEjX5mRzb3vLiRne+HX25GhsnJnwfptVJz8UVRaxuuz1sY8zTmRlXk72VlU/fWu/s8MRj74EdsKS/aYXl7ue02rjo+X5jH4D+N5e+76mPPHzd/I8ryd/PmdhZSUlePuvDhtNR8vzWN/nPxSXu7c++4iXv18LWs2F+wx7735Gygrd3758mw27yzmiqen8fYX6ykqLefz1VsZv2Dj7mULS8r4ZFkenZrXY2tBCVOXb+aJj1ewLHcnDyW4Cdm7X2yguLScxy8ZwPUndWP8whzenbdh9/y52flc9cwMbnhhJms2F/DGnHWkpxltm9TlvXkb99re+AU5mMEDo/rRunEd7n9/MRvyE//tRY9G/cbsdQz5w3jOeehjZqzac9i7rQXFzMneyllhf+PctVtZsH4bvVo35IQemazPL2Rpzo6E77e/qWbxDWBmfPuIqqulTetnMLJfW0b2q3z/qUBamvGTYd04sUcmazYXMLRnFnUzIhSXlnPa/ZP5/Vvz6dS8Pk3r1eL2M/tw4cAO/N//5nLzq3P5/VsLaFQnncb1MjjziNYUFJfyyMRlXDioPbed2YeSMudHT0/juuc/JyN9AKf0aYm7c/dbC2hYpxa/Oq0npeXOz16cRVFJOS0b1+H3by2gVeM6nHZYKyYuyqVurQgDOzeldnpkj3Kvz9/Frf+bS1FpOf/8cAUXDerA9Sd1o3mcJrLCkjI+XJLHgvXbqF87nS4t6jOsV9bu+fkFJVz/wkwmL87lmqFd+cWpPbnxhVm8/cUGBnZqypOXDWJF7k5GT17GT4d3p0fLhntsv7SsnPSwiWNudj7ffeQTTujRgscvHQiw+wAc61vhjFWb+WxFcOB48IOl/N8ZvXev84uXZ/PqzLV0aFaPE3tkcuu3e1OnVmSvbVT29CcrAbj33UWc0qfl7rJVGDN7HbXT01izeRf/nZFNSblz22vB/eWP7tiUu7/Tl16tGiV8n8oqvvlOXpK7+1v6h0vyuGhwMFLztsISpq/cwsBOTZm2cgun/m0SWwpKeObyQXyra3OG/HE8Hy7J44KBwfJTV2ymsKScX4/oxU0vz+bF6WuYuDCHRnXSmbl6K3Oyt3JEuyYxyzJm9jraN6vL8N5ZDO2Zybj5G7nrzQWc2COL4rJyrn1uBs3qZ7CloJj73lvEtJVbOL57C3q2asTjHy7fq0N5/MKN9GvfhNaN6/LT4d255dW5DPnjeI5o15hnLh9Ek3oZZG8p4I9jF/KzU3rQLasBHy7J5ap/z+DEHpkc07U5d74xn8PaNCZ3exHffeRTHr34KEbVm2QBAAAU+ElEQVT0Df6HP1qaR7nDJcd05IOFOXy+aivLcncwtGcWJ4Q1mEmLc+le6W8v2RQWsoe+bRvvcQOnjPQ0bjm9F1f+ewbLcnfyk2FdqVMrwuHtGjPmumP5cEke783fQGFJOas3FXDvu4uAoDP+7nMO332myL+vGMx5j37CL16ezdgbjufFz1bz4ZI8bjuzD03qZexeBoJv8t//51Ruemk2d9dfwPrwW1v9jAjHdmvBsF5ZjDisFU3rZ/DA+0twh2d/NJgxs9bx7ymr+O+MbIb1ymJLQTF1a0U488g2ZDWszUvT1vDOvA0UFO9ZE3r3xhPo2aoh67bu4qJ/TmHt1l0c160Fj0xcxoSFOSzcsJ1z+rXhjTnrOeOBD8neUkC5B807L111DGZBH9Brs9Zy++vzGNSpGf/37d5c+9wMSsvLeX9BDnOz8+nesgEXjP6UZbk76di8HgM6NuV7A9tzWJtgf4+etJzGdWtxfPcWPPnxCi4c1IHOLerz1CcreXXmWs4+sg1FpWX8e8oqNmwr5OHvH1Vl2/v6/F2MX5jDke0aMzs7n1dmZO8xrP7mncV8tCSPK47rzJQVm/nLe4vJ31XM0J6ZDO/dkgfeX8y1//mcsTccT51aEdydxRt38P6CjdTPiDCyX1ua1s/Y4z23FhRz44uz2JBfyL+vGMy/P11Fiwa1SU8zPlqauzssPlqSR2m586sRvXhp2hpenpHNHWf14dhuLQA4tlsLJizMobzcSUszJi7KISM9jaE9sxjWK4s3Zge3xnnhyiFc/tQ0nvl0FXecVZ+HJy7jpF5ZDOwU9Gnkbi/i46V5XDO0K2ZGesS4c2Rfvjf6U874+4fsKCply85iXrxqCO8vyOGRicsA+PkpPeiSWZ9HJy1jwqIczukffMnauK2QOdn5/PK0ngBcOKgDR7ZrwsTFOdzzziKe+XQVPx3enQc/WMpbc9czY9UW/nju4fz0hZk0q5/Bh0vyePuLDRzZrjH/+dFg0sw45a+T+N/MtbvDYtKiXBrVSefIdk04vG1j3v5iPSVlTu/WDWnbpC49Wzbknx8u54QemXTPasD7C3LYWlDM+QOibx+0/yksJKFT+rRkSJdmTFu5hYuHdNw93cw4oUfm7m87ACvydjJrzRbOOqLNHqcU1qkV4cELj+LMf3zEdx76mJztRVwwoD2XfavTXu9XOz3C6B8czcX/+oxm9Wtx18i+mMEHC3OYsDCH9+Zv5J53FnLt0G68NH0Nl36rE8d2a8Gx3Vrw4xM6c++7i5ixagstGtZmycYdvDc/aEpoUDudkf3acHrf1gzq3Izc7UWcdN9EXpy2htvP6sODE5ayLr+Q5388hKM6NOW217/g2amruXZoV341ohcj+rbmppdmMWpQBzo1r8cfxi5k7NwNHNe9Bbe99gVjZq+jd+tGfLg0j5P/OomIGU9dNojrn5/JA+MX06ZJXWZn53Pe0e3I2V7E89PW8PSnqxjQsSkXDGzPuAUbuX5YNy4+piMTFubwo6en0a99U16btZZT+7Tk/gv6kZZmPP3JSu4YM48bX5jFbWf2IbNhbcbMXst78zbSvlk9DmvTiNP7tuaFz9ZQ7s4/LjyKG16cyV/HLWbS4lzmZOdz7bCuGEZpuXPWkW0Y0rU5lz05jXZN63L/Bf1oUi+Dzs3rc/G/pvL38UsYNbAD178wk9lrtu7+Pf1h7EKGdG1O//ZN6NCsHuVhx/D6rYVE0owLRn/Kik07uW5YNzbkF/Le/I2UlTuRNOODhTk0rluL/u2DA+L5A9ozsNOXF5sd370Fr36+lnnrtnF4u8ZMWpTLMV2aUzcjwhl9W/PWnPUM75XFkC7NOfeotrw0PZsZq7awIm8nT368gid/OIhjujZn7Nz1lDt71KgHdW7GT4d3Z/rKzWQ1rM3ph7fm6I7N6JbVkOc/W01BcRmnHNaSBhnpZDWszXvzN+wOi3Hh39Lw3l/WRvu0aUSfNo2YvnILT32ykpH92vDq52sZ1jOTmWu2ctlT02jRoDYvXDmEhrVr8c689Yw4rDUN6wS1lRN7BuFXXFpOelpQGzuuewvSI2kc3q4xnywLzoiqqOHdP6oflzzxGec/+indshowY9UWjmzfhPOObpfUfgxdlCfVkrO9kJV5BQzq/PVOWRwzex0/fX4m5x7Vlr+cd+Q+n6Pu7sxdm89tr33B7Ox86mdEmPSrYXHPzCovDzra83YUMbx3FvUy9vx+dO2zM/h02SbevuEETrx3Auce1ZY/nnvE7vdamrODblkNdv8TVnzTLSt3vv33D8nfVUKaGRu2FXLj8O5cM7Qry/N28rs35nH2kW24YGAH/jF+CfeNWwzAj47rzG/O7AME38Jf/XwtoycvY+O2Imqnp/HxzSfRokFtxsxex6MTl5G7o4iOzerx5GUDdx9cIBhf7M/vLCTNjFaN6rB26y5aNqrNloISikvL6ZJZn227SjmsTSOevnwQU5dvYtQ/p5DVsDZZDeswd20+zetn0LheLcb//EQA/jNlFd/q1oKumQ12v88vw+av+hlBk9cvTuvJiL6t2LSjmJenZ/Px0jwW52yn4jCS2bA2j158NEWlZVz+1DRKypyPfj2Mz1Zs5oYXZvH6T47l8LaNGfSH8RzTtTn/uLB/zN9bzvZCBt09nl+N6MmJPTL59t8/4o6z+nDZsZ3ZVVzG//1vLtcO7Ur3lg1ZvHE7p/5tMq0a1eG3Zx/Gfe8tInvLLkb0bcWU5ZtoXLcW79x4QrX+vt6fv5EN2wp3fym67bUveHH6Gj646URaNarDyX+dRJ1aEd6+4fi9DsyfrdjM90Z/Ssfm9VizuYCJvxjGloJi7n5rAbec0Yv+HWJfef3uvA1c9e8ZPPfjwZSUOZc+8Rn/uLA/Zx3ZhrfmrOcnz31OrYgx/84Ru2uSazYXcOkTn7GjqJQbT+7B+QPaVVnLrIqu4JYaa83mAto2qfu1LmYqLSvn2amradmoztc6g2riohx++OQ0jmjXmDnZ+bz/8xPpltUg8YrAJ8vyuOifU+nYvB73X9Av7sFgW2EJJ9wzgXZN6/Lfa761V79LYUkZz01dTbP6Gbu/wVbH6k0F/GfqKr5Ym8/3B3fk9L6tKHdn4qJc7h67gBV5O/nnJUEfEcCmHUU0rZdBmTs3vTSbMbPXccPw7vzslPh3LM4vKGHEA5NpVj+DR75/NB2a19trmR1FpWzaUYQ7tGxUh7phsMxcvYW1W3dx5hFtyNtRxIDfv88vT+vJ8d1bcPaDH/PX7x3JuUe1i/veI+6fTJ1aEbbtKmFbYQlv33BC3JEKZqzaQpcW9WlaP4Pc7UX85LnPWbd1Fw1qp3PdSd2+8plea7fuYvh9ExneuyVDe2Tyy1fmMPoHR8e8tsLdOfeRT5i5OuicjheEle0oKqX/ne9x+bGdWZ63k5mrt/DJzcPJSE9jzeYCjr9nAr1bN+LtG47fY73i0nLM+MohUUFhIVINZeXO8X/+gHX5hQzvlcW/fjhwn9afk72VrpkNEt4JcUN+IY3qpu9Vs0mWotIy5q/bRr/2TWI2TZSVO+Pmb+TEHpm7D+7x7Couo3Z62te+UvmMB4KaWHFZOfkFJXx6y0lxT0QA+P2b83n8oxWkpxnP/mgwg7s0/1rv/1Xd//5i7n9/CU3r1aJNk7q8ef1xcZt7JizM4er/zOC1nxxL79bVPzHgwsemsGrTTjZsK+TqE4NmTwgCaODd4xnWM5N7zz9yv3yeynTzI5FqiKTZ7o7BHx3fZZ/XP6Jdk2rdMrdV4zoHLCgg6Pfp36Fp3INaJM0Y0bdVwqAAqJsR2S9DWgzvncXarbvo1aohz/14cJVBAXBS2C9w67d7pywoAK46oSttGtdhS0EJPz+lR5X9AsN6ZTH3t6ftU1AE62WyLr8QJ+g0r2BmvHjVEG4Jz4xLJdUs5JC3q7iMz1Zu/koXVkn1FZaUkbOtKGZTVjxrNhfQvln1l0+W6Ss3M3lxLj9LEBZfVUW/y9CemTx12aD9vv2qqBlKROQg4e787f0ljDisFX3a7Pt1LV+HRp0VETlImBk/r+JEg5pAfRYiIpKQwkJERBJSWIiISEIKCxERSUhhISIiCSksREQkIYWFiIgkpLAQEZGEvjFXcJtZLrDqa2yiBZC3n4qTLDW9jDW9fKAy7i8q4/5RE8rY0d0TjnXzjQmLr8vMplfnkvdUqullrOnlA5Vxf1EZ94+DoYwV1AwlIiIJKSxERCQhhcWXHkt1AaqhppexppcPVMb9RWXcPw6GMgLqsxARkWpQzUJERBJSWIiISEKHfFiY2QgzW2RmS83s5lSXB8DM2pvZBDNbYGbzzOyGcHozMxtnZkvCn01rQFkjZjbTzN4MX3c2s6lhGV80s4wUl6+Jmb1iZgvD/XlMTdqPZvaz8Hf8hZk9b2Z1asI+NLMnzCzHzL6ImhZzv1ng7+H/0BwzOypF5bs3/D3PMbP/mVmTqHm3hOVbZGanJbt88coYNe8XZuZm1iJ8fcD34b46pMPCzCLAQ8DpQB/gQjPrk9pSAVAK3OTuvYEhwE/Cct0MjHf37sD48HWq3QAsiHr9Z+BvYRm3AFekpFRfegB4x917AUcSlLVG7Eczawv8FBjg7n2BCDCKmrEPnwJGVJoWb7+dDnQPH1cCj6SofOOAvu5+BLAYuAUg/N8ZBRwWrvNw+L+fijJiZu2BU4DVUZNTsQ/3ySEdFsAgYKm7L3f3YuAFYGSKy4S7r3f3z8Pn2wkOcG0JyvZ0uNjTwDmpKWHAzNoB3wYeD18bcBLwSrhISstoZo2AE4B/Abh7sbtvpWbtx3SgrpmlA/WA9dSAfejuk4HNlSbH228jgWc8MAVoYmatD3T53P09dy8NX04B2kWV7wV3L3L3FcBSgv/9pIqzDwH+BvwKiD676IDvw311qIdFW2BN1OvscFqNYWadgP7AVKClu6+HIFCArNSVDID7Cf7oy8PXzYGtUf+wqd6fXYBc4MmwqexxM6tPDdmP7r4W+AvBN8z1QD4wg5q1D6PF22818f/ocuDt8HmNKZ+ZnQ2sdffZlWbVmDLGc6iHhcWYVmPOJTazBsB/gRvdfVuqyxPNzM4Ectx9RvTkGIumcn+mA0cBj7h7f2AnNaPpDoCwzX8k0BloA9QnaI6orMb8TcZRo37vZnYrQVPusxWTYix2wMtnZvWAW4HbY82OMa1G/d4P9bDIBtpHvW4HrEtRWfZgZrUIguJZd381nLyxomoa/sxJVfmAY4GzzWwlQfPdSQQ1jSZhkwqkfn9mA9nuPjV8/QpBeNSU/XgysMLdc929BHgV+BY1ax9Gi7ffasz/kZldCpwJfN+/vIisppSvK8EXg9nh/0074HMza0XNKWNch3pYTAO6h2efZBB0go1JcZkq2v7/BSxw979GzRoDXBo+vxR4/UCXrYK73+Lu7dy9E8F++8Ddvw9MAM4LF0t1GTcAa8ysZzhpODCfmrMfVwNDzKxe+DuvKF+N2YeVxNtvY4BLwjN6hgD5Fc1VB5KZjQB+DZzt7gVRs8YAo8ystpl1JuhE/uxAl8/d57p7lrt3Cv9vsoGjwr/TGrEPq+Tuh/QDOIPgzIllwK2pLk9YpuMIqqBzgFnh4wyCPoHxwJLwZ7NUlzUs71DgzfB5F4J/xKXAy0DtFJetHzA93JevAU1r0n4EfgcsBL4A/g3Urgn7EHieoB+lhOCgdkW8/UbQhPJQ+D80l+DsrlSUbylBu3/F/8yjUcvfGpZvEXB6qvZhpfkrgRap2of7+tBwHyIiktCh3gwlIiLVoLAQEZGEFBYiIpKQwkJERBJSWIiISEIKC6nxzOyT8GcnM7toP2/7/2K9V7KY2TlmFusK3v2x7f9LvNQ+b/NwM3tqf29XDj46dVYOGmY2FPiFu5+5D+tE3L2sivk73L3B/ihfNcvzCcFFY3lfczt7fa5kfRYzex+43N1XJ1xYvrFUs5Aaz8x2hE//BBxvZrMsuA9EJLyHwbTwHgBXhcsPteB+IM8RXOCEmb1mZjMsuHfEleG0PxGM+DrLzJ6Nfq/wStp7LbjPxFwzuyBq2xPty3tkPBtefY2Z/cnM5odl+UuMz9EDKKoICjN7ysweNbMPzWxxON5WxT1CqvW5orYd67NcbGafhdNGWzgst5ntMLO7zWy2mU0xs5bh9PPDzzvbzCZHbf4Ngqv05VCW6qsC9dAj0QPYEf4cSnilePj6SuA34fPaBFdqdw6X2wl0jlq24mrjugRXSzeP3naM9/ouwf0RIkBLgqE5WofbzicYuycN+JTgivtmBFcHV9TWm8T4HJcB90W9fgp4J9xOd4KrfOvsy+eKVfbweW+Cg3yt8PXDwCXhcwfOCp/fE/Vec4G2lctPMA7YG6n+O9AjtY+KwcpEDkanAkeYWcU4So0JDrrFwGce3Lugwk/N7Dvh8/bhcpuq2PZxwPMeNPVsNLNJwEBgW7jtbAAzmwV0Irh/QiHwuJm9BbwZY5utCYZMj/aSu5cDS8xsOdBrHz9XPMOBo4FpYcWnLl8O/FccVb4ZBDfiAfgYeMrMXiIY1LBCDsGouHIIU1jIwcyA69393T0mBn0bOyu9Phk4xt0LzGwiwTf4RNuOpyjqeRmQ7u6lZjaI4CA9CriOYCTeaLsIDvzRKncaOtX8XAkY8LS73xJjXom7V7xvGeFxwN2vNrPBBDe0mmVm/dx9E8G+2lXN95VvKPVZyMFkO9Aw6vW7wDUWDOeOmfWw4OZGlTUGtoRB0YvgVrUVSirWr2QycEHYf5BJcMe9uCOVWnDvkcbuPha4kWAAw8oWAN0qTTvfzNLMrCvBAIKL9uFzVRb9WcYD55lZVriNZmbWsaqVzayru09199uBPL4cMrsHQdOdHMJUs5CDyRyg1MxmE7T3P0DQBPR52MmcS+xbkL4DXG1mcwgOxlOi5j0GzDGzzz0YYr3C/4BjgNkE3/Z/5e4bwrCJpSHwupnVIfhW/7MYy0wG7jMzi/pmvwiYRNAvcrW7F5rZ49X8XJXt8VnM7DfAe2aWRjDy6U+AVVWsf6+ZdQ/LPz787ADDgLeq8f7yDaZTZ0UOIDN7gKCz+P3w+oU33f2VBKuljJnVJgiz4/zLW73KIUjNUCIH1h+AeqkuxD7oANysoBDVLEREJCHVLEREJCGFhYiIJKSwEBGRhBQWIiKSkMJCREQS+n/rF1MfmqLVswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[42000,8,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D', defined at:\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-f748096b8a05>\", line 1, in <module>\n    Ytest=model(X_train,Y_train,X_test)\n  File \"<ipython-input-33-fa4dabf9a973>\", line 12, in model\n    Z3 = forward_propagation(X,parameters)\n  File \"<ipython-input-31-44512d431e11>\", line 5, in forward_propagation\n    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding=\"SAME\")\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[42000,8,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[42000,8,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-f748096b8a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mYtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-fa4dabf9a973>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m     \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4949\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4950\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4951\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[42000,8,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D', defined at:\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-f748096b8a05>\", line 1, in <module>\n    Ytest=model(X_train,Y_train,X_test)\n  File \"<ipython-input-33-fa4dabf9a973>\", line 12, in model\n    Z3 = forward_propagation(X,parameters)\n  File \"<ipython-input-31-44512d431e11>\", line 5, in forward_propagation\n    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding=\"SAME\")\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\45115\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[42000,8,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "Ytest=model(X_train,Y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
